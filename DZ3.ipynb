{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем данные о корпоративных событиях. Из них для начала надо выбрать данные по датам выхода МСФО отчетности и связать их с котировками и самой отчетностью. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Структура данных при offset=200: <class 'list'>\n",
      "Данные с offset=200 успешно добавлены. Всего записей: 100\n",
      "Структура данных при offset=100: <class 'list'>\n",
      "Данные с offset=100 успешно добавлены. Всего записей: 200\n",
      "Структура данных при offset=0: <class 'list'>\n",
      "Данные с offset=0 успешно добавлены. Всего записей: 300\n",
      "Все данные успешно собраны и сохранены в файле financemarker_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Базовый URL для API\n",
    "base_url = \"https://financemarker.ru/api/fm/v2/disclosure\"\n",
    "api_token = \"\"  # Ваш API-токен\n",
    "limit = 100  # Количество записей на запрос\n",
    "initial_offset = 200  # Начальный offset\n",
    "\n",
    "# Пустой DataFrame для хранения всех данных\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Цикл для уменьшения offset на 100 с каждым запросом\n",
    "for offset in range(initial_offset, -1, -100):\n",
    "    # Параметры запроса\n",
    "    params = {\n",
    "        'limit': limit,\n",
    "        'offset': offset,\n",
    "        'sort_by': 'date',\n",
    "        'sort_order': 'DESC',\n",
    "        'api_token': api_token\n",
    "    }\n",
    "    \n",
    "    # Выполняем запрос к API\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Проверяем, успешно ли выполнен запрос\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        # Выводим структуру данных для отладки\n",
    "        print(f\"Структура данных при offset={offset}: {type(data)}\")\n",
    "        \n",
    "        # Проверка, является ли data списком\n",
    "        if isinstance(data, list):\n",
    "            if len(data) > 0:\n",
    "                # Преобразуем данные в DataFrame\n",
    "                df = pd.DataFrame(data)\n",
    "                # Добавляем данные в общий DataFrame\n",
    "                all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "                print(f\"Данные с offset={offset} успешно добавлены. Всего записей: {len(all_data)}\")\n",
    "            else:\n",
    "                print(f\"Пустые данные с offset={offset}, прекращаем парсинг.\")\n",
    "                break\n",
    "        else:\n",
    "            print(f\"Неожиданный формат данных при offset={offset}: {data}\")\n",
    "            break\n",
    "    else:\n",
    "        print(f\"Ошибка при запросе данных с offset={offset}: {response.status_code}\")\n",
    "        break\n",
    "    \n",
    "    # Пауза между запросами, чтобы избежать блокировки\n",
    "    time.sleep(1)\n",
    "\n",
    "# Сохраняем итоговый DataFrame в Excel\n",
    "all_data.to_excel('new_data.xlsx', index=False)\n",
    "\n",
    "print(\"Все данные успешно собраны и сохранены в файле financemarker_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel('disclosure_data.xlsx')\n",
    "df2 = pd.read_excel('new_data.xlsx')\n",
    "final_data = pd.concat([df1, df2], ignore_index=True)\n",
    "final_data.drop_duplicates(inplace=True)\n",
    "final_data.to_excel('disclosure_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для примера возьмем только отчеты и отчеты только по МСФО по тикерам входящим в состав индекса IMOEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = final_data[final_data['category'] == 'report']\n",
    "filtered_df = filtered_df[filtered_df['type'] == 'МСФО']\n",
    "imoex_base = pd.read_csv('imoex_base.csv') \n",
    "filtered_df = filtered_df[filtered_df['code'].isin(imoex_base['Ticker'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь получаем всю информацию доступную информацию по тикерам из IMOEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные для AFKS успешно получены.\n",
      "Данные для AFLT успешно получены.\n",
      "Данные для AGRO успешно получены.\n",
      "Данные для ALRS успешно получены.\n",
      "Данные для ASTR успешно получены.\n",
      "Данные для BSPB успешно получены.\n",
      "Данные для CBOM успешно получены.\n",
      "Данные для CHMF успешно получены.\n",
      "Данные для ENPG успешно получены.\n",
      "Данные для FEES успешно получены.\n",
      "Данные для FIVE успешно получены.\n",
      "Данные для FLOT успешно получены.\n",
      "Данные для GAZP успешно получены.\n",
      "Данные для GMKN успешно получены.\n",
      "Данные для HYDR успешно получены.\n",
      "Данные для IRAO успешно получены.\n",
      "Данные для LEAS успешно получены.\n",
      "Данные для LKOH успешно получены.\n",
      "Данные для MAGN успешно получены.\n",
      "Данные для MGNT успешно получены.\n",
      "Данные для MOEX успешно получены.\n",
      "Данные для MSNG успешно получены.\n",
      "Данные для MTLR успешно получены.\n",
      "Данные для MTLRP успешно получены.\n",
      "Данные для MTSS успешно получены.\n",
      "Данные для NLMK успешно получены.\n",
      "Данные для NVTK успешно получены.\n",
      "Данные для OZON успешно получены.\n",
      "Данные для PHOR успешно получены.\n",
      "Данные для PIKK успешно получены.\n",
      "Данные для PLZL успешно получены.\n",
      "Данные для POSI успешно получены.\n",
      "Данные для ROSN успешно получены.\n",
      "Данные для RTKM успешно получены.\n",
      "Данные для RUAL успешно получены.\n",
      "Данные для SBER успешно получены.\n",
      "Данные для SBERP успешно получены.\n",
      "Данные для SELG успешно получены.\n",
      "Данные для SMLT успешно получены.\n",
      "Данные для SNGS успешно получены.\n",
      "Данные для SNGSP успешно получены.\n",
      "Данные для TATN успешно получены.\n",
      "Данные для TATNP успешно получены.\n",
      "Данные для TCSG успешно получены.\n",
      "Данные для TRNFP успешно получены.\n",
      "Данные для UPRO успешно получены.\n",
      "Данные для VKCO успешно получены.\n",
      "Данные для VTBR успешно получены.\n",
      "Данные для YDEX успешно получены.\n"
     ]
    }
   ],
   "source": [
    "unique_codes = imoex_base['Ticker'].unique()\n",
    "\n",
    "# Основной URL для запроса\n",
    "url_template = \"https://financemarker.ru/api/fm/v2/stocks/MOEX:{code}\"\n",
    "\n",
    "# Параметры запроса\n",
    "params = {\n",
    "    'include': 'ratios,reports,dividends,ideas,ideasAggregated,info,insiderTransactions,owners,shares,summary',\n",
    "    'api_token': api_token  # Используйте ваш актуальный API токен\n",
    "}\n",
    "\n",
    "# Заголовки запроса\n",
    "headers = {\n",
    "    'accept': 'application/json'\n",
    "}\n",
    "\n",
    "# Создание пустых словарей для хранения данных каждого блока\n",
    "ratios_data = []\n",
    "reports_data = []\n",
    "dividends_data = []\n",
    "ideas_data = []\n",
    "ideas_aggregated_data = []\n",
    "info_data = []\n",
    "insider_transactions_data = []\n",
    "owners_data = []\n",
    "shares_data = []\n",
    "summary_data = []\n",
    "\n",
    "# Функция для добавления данных в соответствующий список\n",
    "def add_data(block_name, data, code):\n",
    "    for item in data:\n",
    "        if item is not None and isinstance(item, dict): \n",
    "            item['code'] = code  # Добавляем код компании к данным\n",
    "            if block_name == 'ratios':\n",
    "                ratios_data.append(item)\n",
    "            elif block_name == 'reports':\n",
    "                reports_data.append(item)\n",
    "            elif block_name == 'dividends':\n",
    "                dividends_data.append(item)\n",
    "            elif block_name == 'ideas':\n",
    "                ideas_data.append(item)\n",
    "            elif block_name == 'ideasAggregated':\n",
    "                ideas_aggregated_data.append(item)\n",
    "            elif block_name == 'info':\n",
    "                info_data.append(item)\n",
    "            elif block_name == 'insiderTransactions':\n",
    "                insider_transactions_data.append(item)\n",
    "            elif block_name == 'owners':\n",
    "                owners_data.append(item)\n",
    "            elif block_name == 'shares':\n",
    "                shares_data.append(item)\n",
    "            elif block_name == 'summary':\n",
    "                summary_data.append(item)\n",
    "\n",
    "# Выполнение запроса для каждого уникального кода\n",
    "for code in unique_codes:\n",
    "    # Формирование URL с подстановкой кода\n",
    "    url = url_template.format(code=code)\n",
    "    \n",
    "    # Выполнение запроса\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    \n",
    "    # Проверка статуса ответа\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        \n",
    "        # Добавление данных в соответствующие списки\n",
    "        for block_name, block_data in data.items():\n",
    "            if isinstance(block_data, list):\n",
    "                add_data(block_name, block_data, code)\n",
    "            else:\n",
    "                add_data(block_name, [block_data], code)  # Если данные не в виде списка\n",
    "        \n",
    "        print(f\"Данные для {code} успешно получены.\")\n",
    "    else:\n",
    "        print(f\"Ошибка при запросе данных для {code}: {response.status_code}\")\n",
    "\n",
    "# Создание DataFrame для каждого блока\n",
    "ratios_df = pd.DataFrame(ratios_data)\n",
    "reports_df = pd.DataFrame(reports_data)\n",
    "dividends_df = pd.DataFrame(dividends_data)\n",
    "ideas_df = pd.DataFrame(ideas_data)\n",
    "ideas_aggregated_df = pd.DataFrame(ideas_aggregated_data)\n",
    "info_df = pd.DataFrame(info_data)\n",
    "insider_transactions_df = pd.DataFrame(insider_transactions_data)\n",
    "owners_df = pd.DataFrame(owners_data)\n",
    "shares_df = pd.DataFrame(shares_data)\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Словарь для хранения DataFrame и соответствующих названий файлов\n",
    "dataframes = {\n",
    "    'ratios': ratios_df,\n",
    "    'reports': reports_df,\n",
    "    'dividends': dividends_df,\n",
    "    'ideas': ideas_df,\n",
    "    'ideasAggregated': ideas_aggregated_df,\n",
    "    'info': info_df,\n",
    "    'insiderTransactions': insider_transactions_df,\n",
    "    'owners': owners_df,\n",
    "    'shares': shares_df,\n",
    "    'summary': summary_df\n",
    "}\n",
    "\n",
    "# Сохранение каждого DataFrame в отдельный Excel файл\n",
    "file_paths = {}\n",
    "for name, df in dataframes.items():\n",
    "    file_name = f\"{name}.xlsx\"\n",
    "    df.to_excel(file_name, index=False)\n",
    "    file_paths[name] = file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь скачиваем котировки акций по API MOEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import backtrader as bt\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Формирование дат начала и конца периода\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=7000)\n",
    "\n",
    "# Преобразование дат в строковый формат\n",
    "start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "# Инициализация переменных для цикла\n",
    "start_index = 0\n",
    "batch_size = 500  # предполагаемое ограничение количества записей на один запрос\n",
    "all_candles_data = []  # список для хранения всех полученных данных\n",
    "for code in unique_codes:\n",
    "    while True:\n",
    "        # URL для запроса данных с учетом start_index\n",
    "        url = f'http://iss.moex.com/iss/engines/stock/markets/shares/boards/TQBR/securities/{code}/candles.json?from={start_date_str}&till={end_date_str}&interval=24&start={start_index}'\n",
    "\n",
    "        # Выполнение запроса\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "\n",
    "        # Извлечение данных свечек\n",
    "        candles_data = data['candles']['data']\n",
    "\n",
    "        # Проверка наличия данных в ответе\n",
    "        if not candles_data:\n",
    "            break  # Выход из цикла, если данных больше нет\n",
    "\n",
    "        # Добавление полученных данных в общий список\n",
    "        all_candles_data.extend(candles_data)\n",
    "\n",
    "        # Увеличение start_index для следующего запроса\n",
    "        start_index += batch_size\n",
    "\n",
    "    # Создание DataFrame из всех полученных данных\n",
    "    df = pd.DataFrame(all_candles_data, columns=data['candles']['columns'])\n",
    "\n",
    "    # Преобразование типов данных для даты и времени\n",
    "    df['begin'] = pd.to_datetime(df['begin'])\n",
    "\n",
    "    df.set_index('begin', inplace=True)\n",
    "\n",
    "    # Переименование столбцов\n",
    "    df = df.rename(columns={'open': 'Open', 'high': 'High', 'low': 'Low', 'close': 'Close', 'volume': 'Volume'})\n",
    "\n",
    "    # Удаление ненужных столбцов\n",
    "    df = df[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "    \n",
    "    df.to_excel(f'{code}.xlsx')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для примера будем работать с reports.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Столбцы, которые будут конвертированы: ['accounts_payable', 'accounts_payable_current', 'accounts_payable_long', 'accounts_receivable', 'accounts_receivable_current', 'accounts_receivable_long', 'amount', 'capex', 'cash_and_equiv', 'cash_paid_for_interest', 'cff', 'cfi', 'cfo', 'commission_expense', 'commission_income', 'commission_net', 'cost_of_sales', 'current_assets', 'current_debt', 'current_lease', 'current_liabilities', 'depr_depl_amort', 'earnings', 'earnings_stock_holders', 'earnings_wo_tax', 'ebit', 'ebitda', 'equity', 'equity_stock_holders', 'fcf', 'ffo', 'goodwill', 'gross_profit', 'interest_expense', 'interest_income', 'interest_net', 'inventories', 'issuance_of_debt', 'long_term_assets', 'long_term_debt', 'long_term_investments', 'long_term_lease', 'long_term_liabilities', 'month', 'net_debt', 'net_issuance_of_debt', 'operating_income', 'payments_for_dividends', 'payments_of_debt', 'property_plant_equipment', 'repurchase_of_stock', 'research_and_development', 'retained_earnings', 'revenue', 'sel_gen_adm_expenses', 'share_premium', 'total_assets', 'total_debt', 'total_expenses', 'total_liabilities', 'year']\n"
     ]
    }
   ],
   "source": [
    "reports_df = pd.read_excel('reports.xlsx')\n",
    "reports_df.columns\n",
    "# Список столбцов для конвертации\n",
    "columns_to_convert = [\n",
    "    'accounts_payable', 'accounts_payable_current', 'accounts_payable_long', \n",
    "    'accounts_receivable', 'accounts_receivable_current', 'accounts_receivable_long', \n",
    "    'amount', 'capex', 'cash_and_equiv', 'cash_paid_for_interest', 'cff', 'cfi', 'cfo', \n",
    "    'commission_expense', 'commission_income', 'commission_net', 'cost_of_sales', \n",
    "    'current_assets', 'current_debt', 'current_lease', 'current_liabilities', \n",
    "    'depr_depl_amort', 'earnings', 'earnings_stock_holders', 'earnings_wo_tax', 'ebit', \n",
    "    'ebitda', 'equity', 'equity_stock_holders', 'fcf', 'ffo', 'goodwill', 'gross_profit', \n",
    "    'interest_expense', 'interest_income', 'interest_net', 'inventories', 'issuance_of_debt', \n",
    "    'long_term_assets', 'long_term_debt', 'long_term_investments', 'long_term_lease', \n",
    "    'long_term_liabilities', 'month', 'net_debt', 'net_issuance_of_debt', 'operating_income', \n",
    "    'payments_for_dividends', 'payments_of_debt', 'property_plant_equipment', \n",
    "    'repurchase_of_stock', 'research_and_development', 'retained_earnings', 'revenue', \n",
    "    'sel_gen_adm_expenses', 'share_premium', 'total_assets', 'total_debt', 'total_expenses', \n",
    "    'total_liabilities', 'year'\n",
    "]\n",
    "\n",
    "# Проверка наличия всех столбцов в DataFrame\n",
    "valid_columns = [col for col in columns_to_convert if col in reports_df.columns]\n",
    "\n",
    "# Вывод списка валидных столбцов, которые будут конвертированы\n",
    "print(f\"Столбцы, которые будут конвертированы: {valid_columns}\")\n",
    "\n",
    "# Преобразование указанных столбцов в числовой формат\n",
    "reports_df[valid_columns] = reports_df[valid_columns].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для простоты оставляем только годовые отчеты по МСФО"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports_df = reports_df[reports_df['type'] == 'МСФО']\n",
    "reports_df = reports_df[reports_df['period'] == 'Y']\n",
    "\n",
    "numeric_columns = reports_df.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "# Умножаем все числовые столбцы на столбец 'amount' (это число на которое надо умножить данные из отчетов)\n",
    "for col in numeric_columns:\n",
    "    if col not in ('year', 'month'):\n",
    "        reports_df[col] = reports_df[col] * reports_df['amount']\n",
    "        \n",
    "disclosure_df = filtered_df[filtered_df['period'] == 'Y']\n",
    "disclosure_df = filtered_df[filtered_df['period'] == 'Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соеденяме информацию из отчетов с их датами выхода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединяем DataFrame по колонкам 'year' и 'code'\n",
    "merged_df = reports_df.merge(disclosure_df[['year', 'code', 'date', 'link']], on=['year', 'code'], how='left')\n",
    "reports_df = merged_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавим признак пропуска данных в датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in reports_df.columns:\n",
    "    reports_df[f'{column}_missing'] = reports_df[column].isnull().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проставляем даты выхода отчета, там где их нет. Если есть пропуск то берем максимальный месяц + день выхода и прибовляем 1 год к отчетному году."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем даты в datetime\n",
    "reports_df['date'] = pd.to_datetime(reports_df['date'], errors='coerce')\n",
    "\n",
    "# Находим самый поздний день и месяц для каждого `code`\n",
    "max_day_month = reports_df.groupby('code')['date'].agg(\n",
    "    lambda x: x.dropna().max()  # Находим самую позднюю дату\n",
    ").reset_index()\n",
    "\n",
    "# Извлекаем день и месяц из самой поздней даты\n",
    "max_day_month['max_day'] = max_day_month['date'].dt.day.fillna(1).astype(int)  # Заполняем NaN значением 1\n",
    "max_day_month['max_month'] = max_day_month['date'].dt.month.fillna(1).astype(int)  # Заполняем NaN значением 1\n",
    "\n",
    "# Объединяем эту информацию с исходным DataFrame\n",
    "reports_df = reports_df.merge(max_day_month[['code', 'max_day', 'max_month']], on='code', how='left')\n",
    "\n",
    "# Заполняем пропущенные даты\n",
    "def fill_missing_dates(row):\n",
    "    if pd.isnull(row['date']):  # Если дата отсутствует\n",
    "        return pd.Timestamp(\n",
    "            year=int(row['year'] + 1), \n",
    "            month=int(row['max_month']), \n",
    "            day=int(row['max_day'])\n",
    "        )\n",
    "    return row['date']  # Если дата есть, оставляем как есть\n",
    "\n",
    "reports_df['date'] = reports_df.apply(fill_missing_dates, axis=1)\n",
    "\n",
    "# Удаляем временные столбцы, если они больше не нужны\n",
    "reports_df.drop(['max_day', 'max_month'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объеденяем котировки по всем тикерам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       begin    Open    High     Low   Close    Volume  code\n",
      "0 2014-06-09  44.364  45.001  43.751  44.448   4380200  AFKS\n",
      "1 2014-06-10  44.440  45.596  44.117  45.499  11586400  AFKS\n",
      "2 2014-06-11  45.007  45.749  44.700  45.300   4757700  AFKS\n",
      "3 2014-06-16  45.913  46.370  44.514  45.999  17932600  AFKS\n",
      "4 2014-06-17  46.300  46.467  45.700  46.100   5544500  AFKS\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Список тикеров\n",
    "final_tickers = reports_df['code'].unique()\n",
    "\n",
    "# Путь к файлам с котировками (в корне проекта)\n",
    "path_to_quotes = \"./\"\n",
    "\n",
    "# Загружаем только те файлы, которые соответствуют тикерам\n",
    "quotes = []\n",
    "for ticker in final_tickers:\n",
    "    file_path = os.path.join(path_to_quotes, f\"{ticker}.xlsx\")\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_excel(file_path)\n",
    "        df['code'] = ticker  # Добавляем тикер как отдельный столбец\n",
    "        quotes.append(df)\n",
    "\n",
    "# Объединяем все котировки в один DataFrame\n",
    "quotes_df = pd.concat(quotes, ignore_index=True)\n",
    "quotes_df['begin'] = pd.to_datetime(quotes_df['begin'])  # Преобразуем даты\n",
    "\n",
    "# Устанавливаем мультииндекс\n",
    "# quotes_df.set_index(['begin', 'code'], inplace=True)\n",
    "\n",
    "# Проверяем результат\n",
    "print(quotes_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         begin    Open    High     Low   Close    Volume  code  \\\n",
      "2   2014-06-09  44.364  45.001  43.751  44.448   4380200  AFKS   \n",
      "15  2014-06-10  44.440  45.596  44.117  45.499  11586400  AFKS   \n",
      "28  2014-06-11  45.007  45.749  44.700  45.300   4757700  AFKS   \n",
      "41  2014-06-16  45.913  46.370  44.514  45.999  17932600  AFKS   \n",
      "54  2014-06-17  46.300  46.467  45.700  46.100   5544500  AFKS   \n",
      "67  2014-06-18  45.823  46.677  45.823  46.600   6390200  AFKS   \n",
      "80  2014-06-19  46.683  47.049  46.113  46.599   2484400  AFKS   \n",
      "93  2014-06-20  46.743  46.763  45.260  46.000   4541800  AFKS   \n",
      "106 2014-06-23  46.091  46.982  45.030  45.500   5511100  AFKS   \n",
      "119 2014-06-24  45.582  46.450  45.261  46.450   8348800  AFKS   \n",
      "132 2014-06-25  46.308  47.332  44.849  45.100   6537800  AFKS   \n",
      "145 2014-06-26  45.497  45.497  44.137  45.200   2746400  AFKS   \n",
      "158 2014-06-27  45.200  46.200  44.623  46.200   4036800  AFKS   \n",
      "171 2014-06-30  46.199  46.338  45.518  45.600   6177400  AFKS   \n",
      "184 2014-07-01  45.517  45.517  44.541  45.143   2769400  AFKS   \n",
      "197 2014-07-02  45.674  45.900  45.121  45.900   5860100  AFKS   \n",
      "210 2014-07-03  45.611  46.448  45.611  46.400   3985100  AFKS   \n",
      "223 2014-07-04  46.395  46.897  46.160  46.600   2954300  AFKS   \n",
      "236 2014-07-07  46.697  48.196  46.301  48.000   8342600  AFKS   \n",
      "249 2014-07-08  48.296  48.729  47.550  47.790  10126900  AFKS   \n",
      "\n",
      "     accounts_payable  accounts_payable_current  accounts_payable_long  ...  \\\n",
      "2                 NaN                       NaN                    NaN  ...   \n",
      "15                NaN                       NaN                    NaN  ...   \n",
      "28                NaN                       NaN                    NaN  ...   \n",
      "41                NaN                       NaN                    NaN  ...   \n",
      "54                NaN                       NaN                    NaN  ...   \n",
      "67                NaN                       NaN                    NaN  ...   \n",
      "80                NaN                       NaN                    NaN  ...   \n",
      "93                NaN                       NaN                    NaN  ...   \n",
      "106               NaN                       NaN                    NaN  ...   \n",
      "119               NaN                       NaN                    NaN  ...   \n",
      "132               NaN                       NaN                    NaN  ...   \n",
      "145               NaN                       NaN                    NaN  ...   \n",
      "158               NaN                       NaN                    NaN  ...   \n",
      "171               NaN                       NaN                    NaN  ...   \n",
      "184               NaN                       NaN                    NaN  ...   \n",
      "197               NaN                       NaN                    NaN  ...   \n",
      "210               NaN                       NaN                    NaN  ...   \n",
      "223               NaN                       NaN                    NaN  ...   \n",
      "236               NaN                       NaN                    NaN  ...   \n",
      "249               NaN                       NaN                    NaN  ...   \n",
      "\n",
      "     sel_gen_adm_expenses_missing  share_premium_missing  \\\n",
      "2                               0                      1   \n",
      "15                              0                      1   \n",
      "28                              0                      1   \n",
      "41                              0                      1   \n",
      "54                              0                      1   \n",
      "67                              0                      1   \n",
      "80                              0                      1   \n",
      "93                              0                      1   \n",
      "106                             0                      1   \n",
      "119                             0                      1   \n",
      "132                             0                      1   \n",
      "145                             0                      1   \n",
      "158                             0                      1   \n",
      "171                             0                      1   \n",
      "184                             0                      1   \n",
      "197                             0                      1   \n",
      "210                             0                      1   \n",
      "223                             0                      1   \n",
      "236                             0                      1   \n",
      "249                             0                      1   \n",
      "\n",
      "     total_assets_missing  total_debt_missing  total_expenses_missing  \\\n",
      "2                       0                   0                       0   \n",
      "15                      0                   0                       0   \n",
      "28                      0                   0                       0   \n",
      "41                      0                   0                       0   \n",
      "54                      0                   0                       0   \n",
      "67                      0                   0                       0   \n",
      "80                      0                   0                       0   \n",
      "93                      0                   0                       0   \n",
      "106                     0                   0                       0   \n",
      "119                     0                   0                       0   \n",
      "132                     0                   0                       0   \n",
      "145                     0                   0                       0   \n",
      "158                     0                   0                       0   \n",
      "171                     0                   0                       0   \n",
      "184                     0                   0                       0   \n",
      "197                     0                   0                       0   \n",
      "210                     0                   0                       0   \n",
      "223                     0                   0                       0   \n",
      "236                     0                   0                       0   \n",
      "249                     0                   0                       0   \n",
      "\n",
      "     total_liabilities_missing  type_missing  year_missing  date_missing  \\\n",
      "2                            0             0             0             1   \n",
      "15                           0             0             0             1   \n",
      "28                           0             0             0             1   \n",
      "41                           0             0             0             1   \n",
      "54                           0             0             0             1   \n",
      "67                           0             0             0             1   \n",
      "80                           0             0             0             1   \n",
      "93                           0             0             0             1   \n",
      "106                          0             0             0             1   \n",
      "119                          0             0             0             1   \n",
      "132                          0             0             0             1   \n",
      "145                          0             0             0             1   \n",
      "158                          0             0             0             1   \n",
      "171                          0             0             0             1   \n",
      "184                          0             0             0             1   \n",
      "197                          0             0             0             1   \n",
      "210                          0             0             0             1   \n",
      "223                          0             0             0             1   \n",
      "236                          0             0             0             1   \n",
      "249                          0             0             0             1   \n",
      "\n",
      "     link_y_missing  \n",
      "2                 1  \n",
      "15                1  \n",
      "28                1  \n",
      "41                1  \n",
      "54                1  \n",
      "67                1  \n",
      "80                1  \n",
      "93                1  \n",
      "106               1  \n",
      "119               1  \n",
      "132               1  \n",
      "145               1  \n",
      "158               1  \n",
      "171               1  \n",
      "184               1  \n",
      "197               1  \n",
      "210               1  \n",
      "223               1  \n",
      "236               1  \n",
      "249               1  \n",
      "\n",
      "[20 rows x 150 columns]\n"
     ]
    }
   ],
   "source": [
    "reports_df['date'] = pd.to_datetime(reports_df['date'])\n",
    "\n",
    "# Добавляем \"end_date\" (до какой даты действует отчет)\n",
    "reports_df['end_date'] = reports_df.groupby('code')['date'].shift(-1)\n",
    "reports_df['end_date'] = reports_df['end_date'].fillna(pd.Timestamp('2099-12-31'))  # Для последнего отчета\n",
    "\n",
    "# Джойним котировки с отчетами\n",
    "merged_df = pd.merge(\n",
    "    quotes_df,\n",
    "    reports_df,\n",
    "    on='code',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Условие: оставляем только строки, где дата попадает в диапазон [date, end_date]\n",
    "merged_df = merged_df[\n",
    "    (merged_df['begin'] >= merged_df['date']) & (merged_df['begin'] < merged_df['end_date'])\n",
    "]\n",
    "\n",
    "# Убираем ненужные столбцы\n",
    "final_df = merged_df.drop(columns=['end_date'])  # Убираем только служебный столбец end_date\n",
    "\n",
    "# Результат\n",
    "print(final_df.head(20))  # Покажем первые 20 строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.set_index(['begin', 'code'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>accounts_payable</th>\n",
       "      <th>accounts_payable_current</th>\n",
       "      <th>accounts_payable_long</th>\n",
       "      <th>accounts_receivable</th>\n",
       "      <th>accounts_receivable_current</th>\n",
       "      <th>...</th>\n",
       "      <th>sel_gen_adm_expenses_missing</th>\n",
       "      <th>share_premium_missing</th>\n",
       "      <th>total_assets_missing</th>\n",
       "      <th>total_debt_missing</th>\n",
       "      <th>total_expenses_missing</th>\n",
       "      <th>total_liabilities_missing</th>\n",
       "      <th>type_missing</th>\n",
       "      <th>year_missing</th>\n",
       "      <th>date_missing</th>\n",
       "      <th>link_y_missing</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>begin</th>\n",
       "      <th>code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-06-09</th>\n",
       "      <th>AFKS</th>\n",
       "      <td>44.364</td>\n",
       "      <td>45.001</td>\n",
       "      <td>43.751</td>\n",
       "      <td>44.448</td>\n",
       "      <td>4380200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-10</th>\n",
       "      <th>AFKS</th>\n",
       "      <td>44.440</td>\n",
       "      <td>45.596</td>\n",
       "      <td>44.117</td>\n",
       "      <td>45.499</td>\n",
       "      <td>11586400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-11</th>\n",
       "      <th>AFKS</th>\n",
       "      <td>45.007</td>\n",
       "      <td>45.749</td>\n",
       "      <td>44.700</td>\n",
       "      <td>45.300</td>\n",
       "      <td>4757700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-16</th>\n",
       "      <th>AFKS</th>\n",
       "      <td>45.913</td>\n",
       "      <td>46.370</td>\n",
       "      <td>44.514</td>\n",
       "      <td>45.999</td>\n",
       "      <td>17932600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-17</th>\n",
       "      <th>AFKS</th>\n",
       "      <td>46.300</td>\n",
       "      <td>46.467</td>\n",
       "      <td>45.700</td>\n",
       "      <td>46.100</td>\n",
       "      <td>5544500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-11</th>\n",
       "      <th>YDEX</th>\n",
       "      <td>7205.500</td>\n",
       "      <td>7235.000</td>\n",
       "      <td>6995.000</td>\n",
       "      <td>7022.500</td>\n",
       "      <td>1556463</td>\n",
       "      <td>1.688650e+11</td>\n",
       "      <td>1.688650e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.503600e+10</td>\n",
       "      <td>8.503600e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-12</th>\n",
       "      <th>YDEX</th>\n",
       "      <td>7025.000</td>\n",
       "      <td>7071.500</td>\n",
       "      <td>6967.000</td>\n",
       "      <td>6990.000</td>\n",
       "      <td>691473</td>\n",
       "      <td>1.688650e+11</td>\n",
       "      <td>1.688650e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.503600e+10</td>\n",
       "      <td>8.503600e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-13</th>\n",
       "      <th>YDEX</th>\n",
       "      <td>6990.000</td>\n",
       "      <td>7048.000</td>\n",
       "      <td>6918.000</td>\n",
       "      <td>6925.000</td>\n",
       "      <td>739997</td>\n",
       "      <td>1.688650e+11</td>\n",
       "      <td>1.688650e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.503600e+10</td>\n",
       "      <td>8.503600e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-14</th>\n",
       "      <th>YDEX</th>\n",
       "      <td>6924.500</td>\n",
       "      <td>7013.500</td>\n",
       "      <td>6900.000</td>\n",
       "      <td>6932.500</td>\n",
       "      <td>872290</td>\n",
       "      <td>1.688650e+11</td>\n",
       "      <td>1.688650e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.503600e+10</td>\n",
       "      <td>8.503600e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-15</th>\n",
       "      <th>YDEX</th>\n",
       "      <td>6932.500</td>\n",
       "      <td>7037.000</td>\n",
       "      <td>6911.000</td>\n",
       "      <td>7021.000</td>\n",
       "      <td>505412</td>\n",
       "      <td>1.688650e+11</td>\n",
       "      <td>1.688650e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.503600e+10</td>\n",
       "      <td>8.503600e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175690 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Open      High       Low     Close    Volume  \\\n",
       "begin      code                                                     \n",
       "2014-06-09 AFKS    44.364    45.001    43.751    44.448   4380200   \n",
       "2014-06-10 AFKS    44.440    45.596    44.117    45.499  11586400   \n",
       "2014-06-11 AFKS    45.007    45.749    44.700    45.300   4757700   \n",
       "2014-06-16 AFKS    45.913    46.370    44.514    45.999  17932600   \n",
       "2014-06-17 AFKS    46.300    46.467    45.700    46.100   5544500   \n",
       "...                   ...       ...       ...       ...       ...   \n",
       "2024-11-11 YDEX  7205.500  7235.000  6995.000  7022.500   1556463   \n",
       "2024-11-12 YDEX  7025.000  7071.500  6967.000  6990.000    691473   \n",
       "2024-11-13 YDEX  6990.000  7048.000  6918.000  6925.000    739997   \n",
       "2024-11-14 YDEX  6924.500  7013.500  6900.000  6932.500    872290   \n",
       "2024-11-15 YDEX  6932.500  7037.000  6911.000  7021.000    505412   \n",
       "\n",
       "                 accounts_payable  accounts_payable_current  \\\n",
       "begin      code                                               \n",
       "2014-06-09 AFKS               NaN                       NaN   \n",
       "2014-06-10 AFKS               NaN                       NaN   \n",
       "2014-06-11 AFKS               NaN                       NaN   \n",
       "2014-06-16 AFKS               NaN                       NaN   \n",
       "2014-06-17 AFKS               NaN                       NaN   \n",
       "...                           ...                       ...   \n",
       "2024-11-11 YDEX      1.688650e+11              1.688650e+11   \n",
       "2024-11-12 YDEX      1.688650e+11              1.688650e+11   \n",
       "2024-11-13 YDEX      1.688650e+11              1.688650e+11   \n",
       "2024-11-14 YDEX      1.688650e+11              1.688650e+11   \n",
       "2024-11-15 YDEX      1.688650e+11              1.688650e+11   \n",
       "\n",
       "                 accounts_payable_long  accounts_receivable  \\\n",
       "begin      code                                               \n",
       "2014-06-09 AFKS                    NaN                  NaN   \n",
       "2014-06-10 AFKS                    NaN                  NaN   \n",
       "2014-06-11 AFKS                    NaN                  NaN   \n",
       "2014-06-16 AFKS                    NaN                  NaN   \n",
       "2014-06-17 AFKS                    NaN                  NaN   \n",
       "...                                ...                  ...   \n",
       "2024-11-11 YDEX                    NaN         8.503600e+10   \n",
       "2024-11-12 YDEX                    NaN         8.503600e+10   \n",
       "2024-11-13 YDEX                    NaN         8.503600e+10   \n",
       "2024-11-14 YDEX                    NaN         8.503600e+10   \n",
       "2024-11-15 YDEX                    NaN         8.503600e+10   \n",
       "\n",
       "                 accounts_receivable_current  ...  \\\n",
       "begin      code                               ...   \n",
       "2014-06-09 AFKS                          NaN  ...   \n",
       "2014-06-10 AFKS                          NaN  ...   \n",
       "2014-06-11 AFKS                          NaN  ...   \n",
       "2014-06-16 AFKS                          NaN  ...   \n",
       "2014-06-17 AFKS                          NaN  ...   \n",
       "...                                      ...  ...   \n",
       "2024-11-11 YDEX                 8.503600e+10  ...   \n",
       "2024-11-12 YDEX                 8.503600e+10  ...   \n",
       "2024-11-13 YDEX                 8.503600e+10  ...   \n",
       "2024-11-14 YDEX                 8.503600e+10  ...   \n",
       "2024-11-15 YDEX                 8.503600e+10  ...   \n",
       "\n",
       "                 sel_gen_adm_expenses_missing  share_premium_missing  \\\n",
       "begin      code                                                        \n",
       "2014-06-09 AFKS                             0                      1   \n",
       "2014-06-10 AFKS                             0                      1   \n",
       "2014-06-11 AFKS                             0                      1   \n",
       "2014-06-16 AFKS                             0                      1   \n",
       "2014-06-17 AFKS                             0                      1   \n",
       "...                                       ...                    ...   \n",
       "2024-11-11 YDEX                             0                      1   \n",
       "2024-11-12 YDEX                             0                      1   \n",
       "2024-11-13 YDEX                             0                      1   \n",
       "2024-11-14 YDEX                             0                      1   \n",
       "2024-11-15 YDEX                             0                      1   \n",
       "\n",
       "                 total_assets_missing  total_debt_missing  \\\n",
       "begin      code                                             \n",
       "2014-06-09 AFKS                     0                   0   \n",
       "2014-06-10 AFKS                     0                   0   \n",
       "2014-06-11 AFKS                     0                   0   \n",
       "2014-06-16 AFKS                     0                   0   \n",
       "2014-06-17 AFKS                     0                   0   \n",
       "...                               ...                 ...   \n",
       "2024-11-11 YDEX                     0                   0   \n",
       "2024-11-12 YDEX                     0                   0   \n",
       "2024-11-13 YDEX                     0                   0   \n",
       "2024-11-14 YDEX                     0                   0   \n",
       "2024-11-15 YDEX                     0                   0   \n",
       "\n",
       "                 total_expenses_missing  total_liabilities_missing  \\\n",
       "begin      code                                                      \n",
       "2014-06-09 AFKS                       0                          0   \n",
       "2014-06-10 AFKS                       0                          0   \n",
       "2014-06-11 AFKS                       0                          0   \n",
       "2014-06-16 AFKS                       0                          0   \n",
       "2014-06-17 AFKS                       0                          0   \n",
       "...                                 ...                        ...   \n",
       "2024-11-11 YDEX                       0                          0   \n",
       "2024-11-12 YDEX                       0                          0   \n",
       "2024-11-13 YDEX                       0                          0   \n",
       "2024-11-14 YDEX                       0                          0   \n",
       "2024-11-15 YDEX                       0                          0   \n",
       "\n",
       "                 type_missing  year_missing date_missing  link_y_missing  \n",
       "begin      code                                                           \n",
       "2014-06-09 AFKS             0             0            1               1  \n",
       "2014-06-10 AFKS             0             0            1               1  \n",
       "2014-06-11 AFKS             0             0            1               1  \n",
       "2014-06-16 AFKS             0             0            1               1  \n",
       "2014-06-17 AFKS             0             0            1               1  \n",
       "...                       ...           ...          ...             ...  \n",
       "2024-11-11 YDEX             0             0            0               0  \n",
       "2024-11-12 YDEX             0             0            0               0  \n",
       "2024-11-13 YDEX             0             0            0               0  \n",
       "2024-11-14 YDEX             0             0            0               0  \n",
       "2024-11-15 YDEX             0             0            0               0  \n",
       "\n",
       "[175690 rows x 148 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
